{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "df = get_titanic_data()\n",
    "df = prep_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex_male  embark_town_Queenstown  embark_town_Southampton  Unnamed: 0  \\\n",
       "0           1                       0                        1           0   \n",
       "1           0                       0                        0           1   \n",
       "2           0                       0                        1           2   \n",
       "3           0                       0                        1           3   \n",
       "4           1                       0                        1           4   \n",
       "..        ...                     ...                      ...         ...   \n",
       "886         1                       0                        1         886   \n",
       "887         0                       0                        1         887   \n",
       "888         0                       0                        1         888   \n",
       "889         1                       0                        0         889   \n",
       "890         1                       1                        0         890   \n",
       "\n",
       "     survived  pclass     sex  sibsp  parch     fare  embark_town  alone  \n",
       "0           0       3    male      1      0   7.2500  Southampton      0  \n",
       "1           1       1  female      1      0  71.2833    Cherbourg      0  \n",
       "2           1       3  female      0      0   7.9250  Southampton      1  \n",
       "3           1       1  female      1      0  53.1000  Southampton      0  \n",
       "4           0       3    male      0      0   8.0500  Southampton      1  \n",
       "..        ...     ...     ...    ...    ...      ...          ...    ...  \n",
       "886         0       2    male      0      0  13.0000  Southampton      1  \n",
       "887         1       1  female      0      0  30.0000  Southampton      1  \n",
       "888         0       3  female      1      2  23.4500  Southampton      0  \n",
       "889         1       1    male      0      0  30.0000    Cherbourg      1  \n",
       "890         0       3    male      0      0   7.7500   Queenstown      1  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 12), (214, 12), (179, 12))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is your baseline prediction? What is your baseline accuracy? \n",
    "# remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode).\n",
    "#  When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n",
    "train_validate, test = train_test_split(df, test_size=.2, \n",
    "                                            random_state=123, \n",
    "                                            stratify=df.survived)\n",
    "train, validate = train_test_split(train_validate, test_size=.3,\n",
    "                                                   random_state=123,\n",
    "                                                   stratify=train_validate.survived)\n",
    "train.shape, validate.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop non-numerical columns\n",
    "drops = ['sex', 'embark_town', 'embark_town_Queenstown', 'embark_town_Southampton', 'Unnamed: 0']\n",
    "[dset.drop(columns=drops, inplace=True) for dset in [train, validate, test]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_male</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex_male  survived  pclass  sibsp  parch      fare  alone\n",
       "583         1         0       1      0      0   40.1250      1\n",
       "165         1         1       3      0      2   20.5250      0\n",
       "50          1         0       3      4      1   39.6875      0\n",
       "259         0         1       2      0      1   26.0000      0\n",
       "306         0         1       1      0      0  110.8833      1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_male</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.2125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133.6500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sex_male  survived  pclass  sibsp  parch      fare  alone\n",
       "610         0         0       3      1      5   31.2750      0\n",
       "424         1         0       3      1      1   20.2125      0\n",
       "568         1         0       3      0      0    7.2292      1\n",
       "334         0         1       1      1      0  133.6500      0\n",
       "101         1         0       3      0      0    7.8958      1"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline prediction -- not survived(0)\n",
    "train.survived.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy is 61.6%\n",
    "(train.survived == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting targets\n",
    "X_train, y_train = train.drop(columns='survived'), train.survived\n",
    "X_validate, y_validate = validate.drop(columns='survived'), validate.survived\n",
    "X_test, y_test = test.drop(columns='survived'), test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score: 0.9417670682730924\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "#Model Score\n",
    "print(\"Model Score:\", clf.score(X_train, y_train))\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[303,   4],\n",
       "       [ 25, 166]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix\")\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.923780    0.976471  0.941767    0.950126      0.943989\n",
      "recall       0.986971    0.869110  0.941767    0.928040      0.941767\n",
      "f1-score     0.954331    0.919668  0.941767    0.936999      0.941036\n",
      "support    307.000000  191.000000  0.941767  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive rate: 0.869 \n",
      "false positive rate:  0.013 \n",
      "true negative rate:  0.987 \n",
      "false negative rate;  0.131\n"
     ]
    }
   ],
   "source": [
    "# Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n",
    "print (f'true positive rate: {tpr:.3} \\nfalse positive rate: {fpr: .3} \\ntrue negative rate: {tnr: .3} \\nfalse negative rate; {fnr: .3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8232931726907631\n",
      "Confusion Matrix\n",
      "[[276  31]\n",
      " [ 57 134]]\n",
      "Classification Report\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.828829    0.812121  0.823293    0.820475      0.822421\n",
      "recall       0.899023    0.701571  0.823293    0.800297      0.823293\n",
      "f1-score     0.862500    0.752809  0.823293    0.807654      0.820430\n",
      "support    307.000000  191.000000  0.823293  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "# Run through steps 2-4 using a different max_depth value.\n",
    "clf1 = DecisionTreeClassifier(max_depth=3)\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Score:\", clf1.score(X_train, y_train))\n",
    "y_pred_1 = clf1.predict(X_train)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "conf = confusion_matrix(y_train, y_pred_1)\n",
    "print(conf)\n",
    "\n",
    "print(\"Classification Report\")\n",
    "report = pd.DataFrame(classification_report(y_train, y_pred_1, output_dict=True))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model performs better on your in-sample data?\n",
    "# Model 1 performs better on the in-sample data with accuracy of 94.18%. Model 2's accuracy score is 82.33% with depth level of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model performs best on your out-of-sample data, the validate set?\n",
    "# model 1\n",
    "y_val_pred = clf.predict(X_validate)\n",
    "# model 2\n",
    "y_val_pred_1 = clf1.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7710280373831776, 0.7850467289719626)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_score = clf.score(X_validate, y_validate)\n",
    "val_score_1 = clf1.score(X_validate, y_validate)\n",
    "val_score, val_score_1\n",
    "# there is a drop in model 1. This suggests over-fit in the training dataset, and the model 2 is higher than model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work through these same exercises using the Telco dataset.\n",
    "# Experiment with this model on other datasets with a higher number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "# Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "# Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) \n",
    "# setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "rf = RandomForestClassifier(max_depth=10, min_samples_leaf=1, random_state=123)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9397590361445783"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "print('Model Score')\n",
    "rf_score = rf.score(X_train, y_train)\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[301,   6],\n",
       "       [ 24, 167]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate,\n",
    "#  false negative rate, precision, recall, f1-score, and support.\n",
    "tpr = conf[1][1] / conf[1].sum()\n",
    "fpr = conf[0][1] / conf[0].sum()\n",
    "tnr = conf[0][0] / conf[0].sum()\n",
    "fnr = conf[1][0] / conf[1].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the model is 0.9398\n",
      "true positive rate: 0.874 \n",
      "false positive rate:  0.0195 \n",
      "true negative rate:  0.98 \n",
      "false negative rate;  0.126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.926154</td>\n",
       "      <td>0.965318</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.945736</td>\n",
       "      <td>0.941175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.980456</td>\n",
       "      <td>0.874346</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.927401</td>\n",
       "      <td>0.939759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.952532</td>\n",
       "      <td>0.917582</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.935057</td>\n",
       "      <td>0.939127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.926154    0.965318  0.939759    0.945736      0.941175\n",
       "recall       0.980456    0.874346  0.939759    0.927401      0.939759\n",
       "f1-score     0.952532    0.917582  0.939759    0.935057      0.939127\n",
       "support    307.000000  191.000000  0.939759  498.000000    498.000000"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'The accuracy for the model is {rf_score:.4}')\n",
    "print (f'true positive rate: {tpr:.3} \\nfalse positive rate: {fpr: .3} \\ntrue negative rate: {tnr: .3} \\nfalse negative rate; {fnr: .3}')\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "rf1 = RandomForestClassifier(min_samples_leaf=3, max_depth=3, random_state=123)\n",
    "rf1.fit(X_train, y_train)\n",
    "y_pred1 = rf1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1 Score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8293172690763052"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model_1 Score')\n",
    "rf_score1 = rf1.score(X_train, y_train)\n",
    "rf_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[284,  23],\n",
       "       [ 62, 129]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "conf1 = confusion_matrix(y_train, y_pred1)\n",
    "conf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "report1 = pd.DataFrame(classification_report(y_train, y_pred1, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the model_1 is 0.8293\n",
      "true positive rate: 0.675 \n",
      "false positive rate:  0.0749 \n",
      "true negative rate:  0.925 \n",
      "false negative rate;  0.325\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820809</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.834747</td>\n",
       "      <td>0.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.925081</td>\n",
       "      <td>0.675393</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.800237</td>\n",
       "      <td>0.829317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.869832</td>\n",
       "      <td>0.752187</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>0.811009</td>\n",
       "      <td>0.824711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.829317</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.820809    0.848684  0.829317    0.834747      0.831500\n",
       "recall       0.925081    0.675393  0.829317    0.800237      0.829317\n",
       "f1-score     0.869832    0.752187  0.829317    0.811009      0.824711\n",
       "support    307.000000  191.000000  0.829317  498.000000    498.000000"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr = conf1[1][1] / conf1[1].sum()\n",
    "fpr = conf1[0][1] / conf1[0].sum()\n",
    "tnr = conf1[0][0] / conf1[0].sum()\n",
    "fnr = conf1[1][0] / conf1[1].sum()\n",
    "print(f'The accuracy for the model_1 is {rf_score1:.4}')\n",
    "print (f'true positive rate: {tpr:.3} \\nfalse positive rate: {fpr: .3} \\ntrue negative rate: {tnr: .3} \\nfalse negative rate; {fnr: .3}')\n",
    "report1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "# model 1 performed worse in terms of accuracy than the first model because it has lower max depth and higher min-sample.\n",
    "# This is due to lower max depth covering less depth of classfication level and higher min-sample putting limitation on the number of samples,\n",
    "# making it less flexible to classify the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in-sample score: 0.9397590361445783\n",
      "Model out-of-sample score: 0.794392523364486\n",
      "Model 1 in-sample score: 0.8293172690763052\n",
      "Model 1 out-of-sample score: 0.794392523364486\n"
     ]
    }
   ],
   "source": [
    "# After making a few models, which one has the best performance (or closest metrics) on both train and validate?\n",
    "print(\"Model in-sample score:\", rf.score(X_train, y_train))\n",
    "print(\"Model out-of-sample score:\", rf.score(X_validate, y_validate))\n",
    "\n",
    "print(\"Model 1 in-sample score:\", rf1.score(X_train, y_train))\n",
    "print(\"Model 1 out-of-sample score:\", rf1.score(X_validate, y_validate))\n",
    "#The out of sample accuracy for both models are identical while the model 1 performed worse than than the model on in -sample accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue working in your model file with the titanic dataset.\n",
    "\n",
    "# Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8052208835341366"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "print('KNN accuracy')\n",
    "score = knn.score(X_train, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[259,  48],\n",
       "       [ 49, 142]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "knn_conf = confusion_matrix(y_train, y_pred)\n",
    "knn_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.840909    0.747368  0.805221    0.794139      0.805033\n",
      "recall       0.843648    0.743455  0.805221    0.793552      0.805221\n",
      "f1-score     0.842276    0.745407  0.805221    0.793842      0.805124\n",
      "support    307.000000  191.000000  0.805221  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy Score for the model is 0.8052\n",
      "true positive rate: 0.743 \n",
      "false positive rate:  0.156 \n",
      "true negative rate:  0.844 \n",
      "false negative rate;  0.257\n"
     ]
    }
   ],
   "source": [
    "# Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, \n",
    "# precision, recall, f1-score, and support.\n",
    "tpr = knn_conf[1][1] / knn_conf[1].sum()\n",
    "fpr = knn_conf[0][1] / knn_conf[0].sum()\n",
    "tnr = knn_conf[0][0] / knn_conf[0].sum()\n",
    "fnr = knn_conf[1][0] / knn_conf[1].sum()\n",
    "print(f'The accuracy Score for the model is {score:.4}')\n",
    "print (f'true positive rate: {tpr:.3} \\nfalse positive rate: {fpr: .3} \\ntrue negative rate: {tnr: .3} \\nfalse negative rate; {fnr: .3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7911646586345381\n",
      "Confusion Matrix\n",
      " [[262  45]\n",
      " [ 59 132]]\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.816199    0.745763  0.791165    0.780981      0.789185\n",
      "recall       0.853420    0.691099  0.791165    0.772260      0.791165\n",
      "f1-score     0.834395    0.717391  0.791165    0.775893      0.789520\n",
      "support    307.000000  191.000000  0.791165  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "# Run through steps 2-4 setting k to 10\n",
    "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_10 = knn_10.fit(X_train, y_train)\n",
    "y_pred10 = knn_10.predict(X_train)\n",
    "\n",
    "print(\"Accuracy Score:\", knn_10.score(X_train, y_train))\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_train, y_pred10))\n",
    "print(pd.DataFrame(classification_report(y_train, y_pred10, output_dict=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7409638554216867\n",
      "Confusion Matrix\n",
      " [[256  51]\n",
      " [ 78 113]]\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.766467    0.689024  0.740964    0.727746      0.736765\n",
      "recall       0.833876    0.591623  0.740964    0.712750      0.740964\n",
      "f1-score     0.798752    0.636620  0.740964    0.717686      0.736569\n",
      "support    307.000000  191.000000  0.740964  498.000000    498.000000\n"
     ]
    }
   ],
   "source": [
    "# Run through setps 2-4 setting k to 20\n",
    "knn_20 = KNeighborsClassifier(n_neighbors=20)\n",
    "knn_20 = knn_20.fit(X_train, y_train)\n",
    "y_pred20 = knn_20.predict(X_train)\n",
    "\n",
    "print(\"Accuracy Score:\", knn_20.score(X_train, y_train))\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(y_train, y_pred20))\n",
    "print(pd.DataFrame(classification_report(y_train, y_pred20, output_dict=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "#  The higher the n-neighbors, the lesser the accuracy score. The first model performs the best as the default n-neighbor is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn in-sample score: 0.8052208835341366\n",
      "knn out-of-sample score: 0.7429906542056075 \n",
      "\n",
      "knn_10 in-sample score: 0.7911646586345381\n",
      "knn_10 out-of-sample score: 0.7149532710280374 \n",
      "\n",
      "knn_20 in-sample score: 0.7409638554216867\n",
      "knn_20 out-of-sample score: 0.6682242990654206\n"
     ]
    }
   ],
   "source": [
    "# Which model performs best on our out-of-sample data from validate?\n",
    "print(\"knn in-sample score:\", knn.score(X_train, y_train))\n",
    "print(\"knn out-of-sample score:\", knn.score(X_validate, y_validate), \"\\n\")\n",
    "\n",
    "print(\"knn_10 in-sample score:\", knn_10.score(X_train, y_train))\n",
    "print(\"knn_10 out-of-sample score:\", knn_10.score(X_validate, y_validate), \"\\n\")\n",
    "\n",
    "print(\"knn_20 in-sample score:\", knn_20.score(X_train, y_train))\n",
    "print(\"knn_20 out-of-sample score:\", knn_20.score(X_validate, y_validate))\n",
    "# The first model performs best on the out-of-sample data from validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In these exercises, we'll continue working with the titanic dataset and building logistic regression models. \n",
    "# Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. \n",
    "# The test dataset should only be used for your final model.\n",
    "\n",
    "# For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "# Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. \n",
    "# Add, commit, and push your work.\n",
    "\n",
    "# Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?\n",
    "\n",
    "# Include sex in your model as well. \n",
    "# Note that you'll need to encode or create a dummy variable of this feature before including it in a model.\n",
    "\n",
    "# Try out other combinations of features and models.\n",
    "\n",
    "# Use you best 3 models to predict and evaluate on your validate sample.\n",
    "\n",
    "# Choose you best model from the validation performation, and evaluate it on the test dataset. \n",
    "# How do the performance metrics compare to validate? to train?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
